{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USE-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioJKWN57SXM7"
      },
      "source": [
        "!pip install tensorflow_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tg8Aj10LCJn"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD3B9WvyNffB"
      },
      "source": [
        "dir_path = 'XFORMAL'\n",
        "file_path = dir_path + '.zip'\n",
        "if not os.path.isdir(dir_path):\n",
        "    if not os.path.isfile(file_path):\n",
        "        !wget -O XFORMAL.zip \"https://docs.google.com/uc?export=download&id=1cF8AXSQ1OZhgIbaIBWc3n8xgj2_prY8C\"\n",
        "    !7z x XFORMAL.zip\n",
        "\n",
        "    for i in glob('XFORMAL/gyafc_translated/*/*/*/'):\n",
        "        list_files = os.listdir(i)\n",
        "        informal_path = os.path.join(i, '1_informal')\n",
        "        os.mkdir(informal_path)\n",
        "        formal_path = os.path.join(i, '1_formal')\n",
        "        os.mkdir(formal_path)\n",
        "        for j in list_files:\n",
        "            if 'informal' in j:\n",
        "                os.rename(\n",
        "                    os.path.join(i, j),\n",
        "                    os.path.join(informal_path, j),\n",
        "                )\n",
        "            else:\n",
        "                os.rename(\n",
        "                    os.path.join(i, j),\n",
        "                    os.path.join(formal_path, j),\n",
        "                )\n",
        "        os.rename(informal_path, os.path.join(i, 'informal'))\n",
        "        os.rename(formal_path, os.path.join(i, 'formal'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zPyCr16Q7zk"
      },
      "source": [
        "def get_label(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "\n",
        "    # Note: You'll use indexing here instead of tuple unpacking to enable this \n",
        "    # to work in a TensorFlow graph.\n",
        "    return parts[-2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCYRCPtqfNno"
      },
      "source": [
        "class_names = ['formal', 'informal']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzKgjSefMro"
      },
      "source": [
        "def labeler(example, example_path):\n",
        "    return example, tf.argmax(get_label(example_path) == class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Rtkg6uWKbm"
      },
      "source": [
        "data_path = 'XFORMAL/gyafc_translated/{}/*/{}/*/*'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghjBSrJ0hwDK"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "BUFFER_SIZE = 200000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzSL9woWa77L"
      },
      "source": [
        "def create(path_dataset, train=False):\n",
        "    labeled_data_sets = []\n",
        "\n",
        "    for file_name in glob(path_dataset):\n",
        "        lines_dataset = tf.data.TextLineDataset(file_name)\n",
        "        labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, file_name))\n",
        "        labeled_data_sets.append(labeled_dataset)\n",
        "    \n",
        "    all_labeled_data = labeled_data_sets[0]\n",
        "    for labeled_dataset in labeled_data_sets[1:]:\n",
        "        all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
        "    if train:\n",
        "        all_labeled_data = all_labeled_data.shuffle(BUFFER_SIZE)\n",
        "    all_labeled_data = all_labeled_data.batch(BATCH_SIZE)\n",
        "    return all_labeled_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeQfVVaISlF4"
      },
      "source": [
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=[], dtype=tf.string),\n",
        "        hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\", trainable=True),\n",
        "        tf.keras.layers.Dense(512, \"relu\"),\n",
        "        tf.keras.layers.Dropout(.5),\n",
        "        tf.keras.layers.Dense(256, \"relu\"),\n",
        "        tf.keras.layers.Dropout(.5),\n",
        "        tf.keras.layers.Dense(1, 'sigmoid'),\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYXdvM7AX7MN"
      },
      "source": [
        "langs = ['en', 'fr', 'it', 'pt', 'ru']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWkrkvzdYnet"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69AyhiqcX5_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd894ac0-3fee-4a88-d2ea-d6b0a219c90f"
      },
      "source": [
        "for lang in list(reversed(langs)):\n",
        "    print(lang)\n",
        "    train_dataset = create(data_path.format(lang, 'train'), True)\n",
        "    valid_dataset = create(data_path.format(lang, 'test'))\n",
        "\n",
        "    model = create_model()\n",
        "    # Create earlystopping callback\n",
        "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', min_delta=0,\n",
        "        patience=2, restore_best_weights = True)\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=1024,\n",
        "        callbacks=[early_stopping_callback]\n",
        "    )\n",
        "\n",
        "    tune_dataset = create(data_path.format(lang, 'tune'))\n",
        "\n",
        "    y_test = np.concatenate([y for x, y in tune_dataset], axis=0)\n",
        "\n",
        "    y_pred = model.predict(tune_dataset)\n",
        "\n",
        "    test_predict_around = np.around(y_pred)\n",
        "\n",
        "    result = classification_report(y_test, test_predict_around, digits=6)\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ru\n",
            "Epoch 1/1024\n",
            "409/409 [==============================] - 48s 85ms/step - loss: 0.3583 - accuracy: 0.8434 - val_loss: 0.4042 - val_accuracy: 0.8240\n",
            "Epoch 2/1024\n",
            "409/409 [==============================] - 36s 81ms/step - loss: 0.3059 - accuracy: 0.8641 - val_loss: 0.4180 - val_accuracy: 0.8274\n",
            "Epoch 3/1024\n",
            "409/409 [==============================] - 36s 81ms/step - loss: 0.2750 - accuracy: 0.8770 - val_loss: 0.4426 - val_accuracy: 0.8210\n",
            "Epoch 4/1024\n",
            "409/409 [==============================] - 36s 82ms/step - loss: 0.2438 - accuracy: 0.8915 - val_loss: 0.4725 - val_accuracy: 0.8151\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.761061  0.931262  0.837603     27263\n",
            "           1   0.895773  0.668937  0.765913     24077\n",
            "\n",
            "    accuracy                       0.808239     51340\n",
            "   macro avg   0.828417  0.800100  0.801758     51340\n",
            "weighted avg   0.824237  0.808239  0.803982     51340\n",
            "\n",
            "pt\n",
            "Epoch 1/1024\n",
            "409/409 [==============================] - 46s 80ms/step - loss: 0.3886 - accuracy: 0.8187 - val_loss: 0.4171 - val_accuracy: 0.7985\n",
            "Epoch 2/1024\n",
            "409/409 [==============================] - 35s 79ms/step - loss: 0.3261 - accuracy: 0.8468 - val_loss: 0.4306 - val_accuracy: 0.8090\n",
            "Epoch 3/1024\n",
            "409/409 [==============================] - 34s 78ms/step - loss: 0.2912 - accuracy: 0.8626 - val_loss: 0.4546 - val_accuracy: 0.8057\n",
            "Epoch 4/1024\n",
            "409/409 [==============================] - 34s 78ms/step - loss: 0.2570 - accuracy: 0.8797 - val_loss: 0.4832 - val_accuracy: 0.7987\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.721094  0.939038  0.815760     27263\n",
            "           1   0.895056  0.588736  0.710277     24077\n",
            "\n",
            "    accuracy                       0.774757     51340\n",
            "   macro avg   0.808075  0.763887  0.763019     51340\n",
            "weighted avg   0.802677  0.774757  0.766292     51340\n",
            "\n",
            "it\n",
            "Epoch 1/1024\n",
            "409/409 [==============================] - 46s 80ms/step - loss: 0.3825 - accuracy: 0.8235 - val_loss: 0.4075 - val_accuracy: 0.8125\n",
            "Epoch 2/1024\n",
            "409/409 [==============================] - 34s 77ms/step - loss: 0.3224 - accuracy: 0.8495 - val_loss: 0.4507 - val_accuracy: 0.8125\n",
            "Epoch 3/1024\n",
            "409/409 [==============================] - 34s 78ms/step - loss: 0.2848 - accuracy: 0.8663 - val_loss: 0.4370 - val_accuracy: 0.7994\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.735999  0.925027  0.819757     27263\n",
            "           1   0.880293  0.624289  0.730511     24077\n",
            "\n",
            "    accuracy                       0.783989     51340\n",
            "   macro avg   0.808146  0.774658  0.775134     51340\n",
            "weighted avg   0.803669  0.783989  0.777903     51340\n",
            "\n",
            "fr\n",
            "Epoch 1/1024\n",
            "409/409 [==============================] - 48s 85ms/step - loss: 0.3475 - accuracy: 0.8460 - val_loss: 0.3886 - val_accuracy: 0.8257\n",
            "Epoch 2/1024\n",
            "409/409 [==============================] - 36s 83ms/step - loss: 0.2882 - accuracy: 0.8704 - val_loss: 0.4350 - val_accuracy: 0.8258\n",
            "Epoch 3/1024\n",
            "409/409 [==============================] - 36s 82ms/step - loss: 0.2550 - accuracy: 0.8851 - val_loss: 0.4264 - val_accuracy: 0.8257\n",
            "Epoch 4/1024\n",
            "409/409 [==============================] - 37s 83ms/step - loss: 0.2249 - accuracy: 0.8982 - val_loss: 0.4890 - val_accuracy: 0.8150\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.774422  0.905770  0.834962     27263\n",
            "           1   0.867938  0.701250  0.775741     24077\n",
            "\n",
            "    accuracy                       0.809856     51340\n",
            "   macro avg   0.821180  0.803510  0.805351     51340\n",
            "weighted avg   0.818278  0.809856  0.807189     51340\n",
            "\n",
            "en\n",
            "Epoch 1/1024\n",
            "409/409 [==============================] - 45s 79ms/step - loss: 0.2378 - accuracy: 0.9059 - val_loss: 0.2736 - val_accuracy: 0.8902\n",
            "Epoch 2/1024\n",
            "409/409 [==============================] - 34s 76ms/step - loss: 0.1649 - accuracy: 0.9323 - val_loss: 0.3120 - val_accuracy: 0.8932\n",
            "Epoch 3/1024\n",
            "409/409 [==============================] - 34s 77ms/step - loss: 0.1352 - accuracy: 0.9445 - val_loss: 0.3536 - val_accuracy: 0.8941\n",
            "Epoch 4/1024\n",
            "409/409 [==============================] - 34s 76ms/step - loss: 0.1115 - accuracy: 0.9555 - val_loss: 0.3548 - val_accuracy: 0.8879\n",
            "Epoch 5/1024\n",
            "409/409 [==============================] - 34s 76ms/step - loss: 0.0919 - accuracy: 0.9637 - val_loss: 0.4179 - val_accuracy: 0.8861\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.832146  0.942303  0.883805     27263\n",
            "           1   0.923148  0.784774  0.848356     24077\n",
            "\n",
            "    accuracy                       0.868426     51340\n",
            "   macro avg   0.877647  0.863538  0.866080     51340\n",
            "weighted avg   0.874823  0.868426  0.867180     51340\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6T7ytRbnItB"
      },
      "source": [
        "langs = ['en', 'fr', 'it', 'pt', 'ru']\n",
        "lang_format = '[!{}]*'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8zoaU0i06r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5268dabb-4ad9-4aa8-83f1-eb61464109f0"
      },
      "source": [
        "for lang in langs:\n",
        "    print(lang)\n",
        "    tune_dataset = create(data_path.format(lang, 'tune'))\n",
        "    y_test = np.concatenate([y for x, y in tune_dataset], axis=0)\n",
        "\n",
        "    y_pred = model.predict(tune_dataset)\n",
        "\n",
        "    test_predict_around = np.around(y_pred)\n",
        "\n",
        "    result = classification_report(y_test, test_predict_around, digits=6)\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.838003  0.950042  0.890512     27263\n",
            "           1   0.933340  0.792042  0.856905     24077\n",
            "\n",
            "    accuracy                       0.875945     51340\n",
            "   macro avg   0.885671  0.871042  0.873709     51340\n",
            "weighted avg   0.882713  0.875945  0.874752     51340\n",
            "\n",
            "fr\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.780935  0.901185  0.836762     27263\n",
            "           1   0.864480  0.713752  0.781918     24077\n",
            "\n",
            "    accuracy                       0.813284     51340\n",
            "   macro avg   0.822708  0.807468  0.809340     51340\n",
            "weighted avg   0.820115  0.813284  0.811042     51340\n",
            "\n",
            "it\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.757978  0.876499  0.812941     27263\n",
            "           1   0.830070  0.683100  0.749447     24077\n",
            "\n",
            "    accuracy                       0.785801     51340\n",
            "   macro avg   0.794024  0.779800  0.781194     51340\n",
            "weighted avg   0.791787  0.785801  0.783164     51340\n",
            "\n",
            "pt\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.741496  0.893152  0.810289     27263\n",
            "           1   0.842549  0.647423  0.732209     24077\n",
            "\n",
            "    accuracy                       0.777912     51340\n",
            "   macro avg   0.792023  0.770287  0.771249     51340\n",
            "weighted avg   0.788887  0.777912  0.773672     51340\n",
            "\n",
            "ru\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.778152  0.890951  0.830740     27263\n",
            "           1   0.852273  0.712381  0.776073     24077\n",
            "\n",
            "    accuracy                       0.807207     51340\n",
            "   macro avg   0.815212  0.801666  0.803407     51340\n",
            "weighted avg   0.812913  0.807207  0.805103     51340\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bbwt9c8mmIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b1482b-f029-47f6-e00f-d6e07565dcae"
      },
      "source": [
        "for lang in langs:\n",
        "    print(lang)\n",
        "    train_dataset = create(data_path.format(lang_format.format(lang), 'train'), True)\n",
        "    valid_dataset = create(data_path.format(lang, 'test'))\n",
        "\n",
        "    model = create_model()\n",
        "    # Create earlystopping callback\n",
        "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', min_delta=0,\n",
        "        patience=2, restore_best_weights = True)\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=1024,\n",
        "        callbacks=[early_stopping_callback]\n",
        "    )\n",
        "\n",
        "    tune_dataset = create(data_path.format(lang, 'tune'))\n",
        "\n",
        "    y_test = np.concatenate([y for x, y in tune_dataset], axis=0)\n",
        "\n",
        "    y_pred = model.predict(tune_dataset)\n",
        "\n",
        "    test_predict_around = np.around(y_pred)\n",
        "\n",
        "    result = classification_report(y_test, test_predict_around, digits=6)\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en\n",
            "Epoch 1/1024\n",
            "1634/1634 [==============================] - 145s 81ms/step - loss: 0.3365 - accuracy: 0.8456 - val_loss: 0.4547 - val_accuracy: 0.7674\n",
            "Epoch 2/1024\n",
            "1634/1634 [==============================] - 133s 80ms/step - loss: 0.2889 - accuracy: 0.8666 - val_loss: 0.4528 - val_accuracy: 0.7962\n",
            "Epoch 3/1024\n",
            "1634/1634 [==============================] - 131s 79ms/step - loss: 0.2554 - accuracy: 0.8820 - val_loss: 0.5339 - val_accuracy: 0.7572\n",
            "Epoch 4/1024\n",
            "1634/1634 [==============================] - 132s 79ms/step - loss: 0.2260 - accuracy: 0.8955 - val_loss: 0.6521 - val_accuracy: 0.7635\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.863069  0.737960  0.795626     27263\n",
            "           1   0.745121  0.867425  0.801635     24077\n",
            "\n",
            "    accuracy                       0.798675     51340\n",
            "   macro avg   0.804095  0.802693  0.798631     51340\n",
            "weighted avg   0.807755  0.798675  0.798444     51340\n",
            "\n",
            "fr\n",
            "Epoch 1/1024\n",
            "1226/1226 [==============================] - 107s 78ms/step - loss: 0.3042 - accuracy: 0.8611 - val_loss: 0.6181 - val_accuracy: 0.6932\n",
            "Epoch 2/1024\n",
            "1226/1226 [==============================] - 96s 76ms/step - loss: 0.2518 - accuracy: 0.8834 - val_loss: 0.5564 - val_accuracy: 0.7253\n",
            "Epoch 3/1024\n",
            "1226/1226 [==============================] - 96s 76ms/step - loss: 0.2186 - accuracy: 0.8986 - val_loss: 0.5878 - val_accuracy: 0.7173\n",
            "Epoch 4/1024\n",
            "1226/1226 [==============================] - 96s 77ms/step - loss: 0.1904 - accuracy: 0.9120 - val_loss: 0.6958 - val_accuracy: 0.7057\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.805126  0.624509  0.703408     27263\n",
            "           1   0.660948  0.828841  0.735434     24077\n",
            "\n",
            "    accuracy                       0.720335     51340\n",
            "   macro avg   0.733037  0.726675  0.719421     51340\n",
            "weighted avg   0.737511  0.720335  0.718427     51340\n",
            "\n",
            "it\n",
            "Epoch 1/1024\n",
            "1634/1634 [==============================] - 143s 80ms/step - loss: 0.3001 - accuracy: 0.8657 - val_loss: 0.4344 - val_accuracy: 0.7974\n",
            "Epoch 2/1024\n",
            "1634/1634 [==============================] - 131s 79ms/step - loss: 0.2539 - accuracy: 0.8851 - val_loss: 0.4737 - val_accuracy: 0.7754\n",
            "Epoch 3/1024\n",
            "1634/1634 [==============================] - 132s 79ms/step - loss: 0.2256 - accuracy: 0.8975 - val_loss: 0.5113 - val_accuracy: 0.7509\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.736894  0.885229  0.804279     27263\n",
            "           1   0.831675  0.642107  0.724699     24077\n",
            "\n",
            "    accuracy                       0.771212     51340\n",
            "   macro avg   0.784284  0.763668  0.764489     51340\n",
            "weighted avg   0.781343  0.771212  0.766958     51340\n",
            "\n",
            "pt\n",
            "Epoch 1/1024\n",
            "1634/1634 [==============================] - 143s 80ms/step - loss: 0.2994 - accuracy: 0.8664 - val_loss: 0.4484 - val_accuracy: 0.7809\n",
            "Epoch 2/1024\n",
            "1634/1634 [==============================] - 130s 78ms/step - loss: 0.2525 - accuracy: 0.8859 - val_loss: 0.4946 - val_accuracy: 0.7483\n",
            "Epoch 3/1024\n",
            "1634/1634 [==============================] - 131s 79ms/step - loss: 0.2230 - accuracy: 0.8990 - val_loss: 0.5982 - val_accuracy: 0.7228\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.740744  0.824891  0.780556     27263\n",
            "           1   0.772450  0.673091  0.719355     24077\n",
            "\n",
            "    accuracy                       0.753701     51340\n",
            "   macro avg   0.756597  0.748991  0.749956     51340\n",
            "weighted avg   0.755613  0.753701  0.751855     51340\n",
            "\n",
            "ru\n",
            "Epoch 1/1024\n",
            "1634/1634 [==============================] - 140s 78ms/step - loss: 0.3015 - accuracy: 0.8626 - val_loss: 0.5979 - val_accuracy: 0.7111\n",
            "Epoch 2/1024\n",
            "1634/1634 [==============================] - 129s 78ms/step - loss: 0.2523 - accuracy: 0.8840 - val_loss: 0.6098 - val_accuracy: 0.7244\n",
            "Epoch 3/1024\n",
            "1634/1634 [==============================] - 129s 77ms/step - loss: 0.2213 - accuracy: 0.8979 - val_loss: 0.6492 - val_accuracy: 0.7025\n",
            "Epoch 4/1024\n",
            "1634/1634 [==============================] - 129s 77ms/step - loss: 0.1965 - accuracy: 0.9096 - val_loss: 0.6556 - val_accuracy: 0.6950\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.778417  0.650332  0.708633     27263\n",
            "           1   0.666247  0.790381  0.723024     24077\n",
            "\n",
            "    accuracy                       0.716011     51340\n",
            "   macro avg   0.722332  0.720356  0.715829     51340\n",
            "weighted avg   0.725812  0.716011  0.715382     51340\n",
            "\n"
          ]
        }
      ]
    }
  ]
}