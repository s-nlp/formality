{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5985c7f-fbb7-4981-b58d-e1d00c7f5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a82c4b1-7918-42c7-82cd-fc7d187c0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_nli\n",
    "from data import load_gyafc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from transformers import (DebertaTokenizer,\n",
    "                          DebertaForSequenceClassification,\n",
    "                          AutoModelForSequenceClassification,  \n",
    "                          AutoTokenizer,\n",
    "                          Trainer,TrainingArguments)\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5d22f4-284e-4393-9b6f-b8525c9767f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ede00a-ad93-40bb-8497-a5efb9d65681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(model_name):\n",
    "    tr_val_test_datasets = load_gyafc(model_name, toy = False)\n",
    "    _, _, test_dataset = tr_val_test_datasets\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589d8ef4-a71c-446a-a454-d52184d03447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(model_name):\n",
    "    if \"deberta-large\" in model_name:\n",
    "        return \"microsoft/deberta-large\"\n",
    "    elif \"deberta-base\" in model_name:\n",
    "        return \"microsoft/deberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06e93d3-b7b2-40c9-a5ea-f1f60af7aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dict = {}\n",
    "for mt in [\"microsoft/deberta-large\",\"microsoft/deberta-base\"]:\n",
    "    test_dataset_dict[mt] = get_test_dataset(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cd600d-4797-4d26-b6a6-eab02745770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(trained_models_fld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a523bc91-01d2-4500-a4bc-8131981919f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped microsoft_deberta-base_ep10_wus100_lr1e-06\n",
      "dropped microsoft_deberta-base_ep10_wus1000_lr5e-05\n",
      "dropped microsoft_deberta-base_ep10_wus2000_lr1e-06\n",
      "dropped microsoft_deberta-base_ep10_wus2000_lr5e-05\n",
      "dropped microsoft_deberta-base_ep5_wus1000_lr1e-05\n",
      "dropped microsoft_deberta-base_ep10_wus2000_lr1e-05\n",
      "dropped microsoft_deberta-base_ep10_wus1000_lr0.0001\n",
      "dropped microsoft_deberta-base_ep10_wus1000_lr1e-05\n",
      "dropped microsoft_deberta-base_ep5_wus100_lr1e-05\n",
      "dropped microsoft_deberta-base_ep10_wus2000_lr0.0001\n",
      "dropped microsoft_deberta-base_ep5_wus2000_lr5e-05\n",
      "dropped microsoft_deberta-base_ep5_wus1000_lr1e-06\n",
      "dropped microsoft_deberta-base_ep5_wus2000_lr1e-05\n",
      "dropped microsoft_deberta-large_ep5_wus100_lr0.0001\n",
      "dropped microsoft_deberta-large_ep5_wus100_lr1e-05\n",
      "dropped microsoft_deberta-large_ep10_wus100_lr0.0001\n",
      "dropped microsoft_deberta-base_ep5_wus100_lr1e-06\n",
      "dropped microsoft_deberta-base_ep10_wus100_lr0.0001\n",
      "dropped microsoft_deberta-base_ep5_wus100_lr5e-05\n",
      "dropped microsoft_deberta-large_ep5_wus100_lr5e-05\n",
      "dropped microsoft_deberta-base_ep5_wus100_lr0.0001\n",
      "dropped microsoft_deberta-base_ep5_wus2000_lr1e-06\n",
      "dropped microsoft_deberta-base_ep5_wus1000_lr5e-05\n",
      "dropped microsoft_deberta-base_ep10_wus1000_lr1e-06\n",
      "dropped microsoft_deberta-base_ep5_wus2000_lr0.0001\n",
      "dropped microsoft_deberta-base_ep10_wus100_lr1e-05\n",
      "microsoft_deberta-large_ep5_wus100_lr1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 650/650 [01:07<00:00,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped microsoft_deberta-base_ep10_wus100_lr5e-05\n",
      "dropped microsoft_deberta-base_ep5_wus1000_lr0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_models_fld = \"../trained_models/\"\n",
    "\n",
    "existing_inference_results = os.listdir(\"test_results/\")\n",
    "\n",
    "for model_folder in os.listdir(trained_models_fld):\n",
    "    \n",
    "    if f\"{model_folder}.json\" not in existing_inference_results:\n",
    "        \n",
    "        print(model_folder)\n",
    "        \n",
    "        model_type = get_model_type(model_folder)\n",
    "        current_test_dataset = test_dataset_dict[model_type]      \n",
    "        \n",
    "        test_dataloader = DataLoader(\n",
    "            current_test_dataset,\n",
    "            batch_size=64,\n",
    "            # num_workers=4,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        model_folder_abs = os.path.join(trained_models_fld, model_folder)        \n",
    "        test_model = AutoModelForSequenceClassification.from_pretrained(f\"{model_folder_abs}/nli_model/\")\n",
    "        test_model = test_model.to(device)\n",
    "\n",
    "        list_predited_label = []\n",
    "        list_label = []\n",
    "        with torch.no_grad():\n",
    "            for d in tqdm(test_dataloader):\n",
    "                input_ids = d[\"input_ids\"].to(device) # .reshape(64, 24)\n",
    "                attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "                outputs = test_model(input_ids, attention_mask)\n",
    "                logits = outputs[0]\n",
    "\n",
    "                _, prediction = torch.max(logits, dim=1)\n",
    "                targets = d[\"labels\"].detach().numpy().tolist()\n",
    "                prediction = prediction.cpu().detach().numpy().tolist()\n",
    "\n",
    "                list_label.extend(targets)\n",
    "                list_predited_label.extend(prediction)\n",
    "\n",
    "            with open(f\"test_results/{model_folder}.json\", \"w\") as f:\n",
    "                json.dump(list_predited_label, f)\n",
    "    else:\n",
    "        print(\"dropped\", model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33db3575-cde3-4e9f-825d-6e0fd9dc7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"GYAFC_test_labels.json\", \"w\") as f:\n",
    "#     json.dump(list_label, f)\n",
    "\n",
    "# len(list_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
