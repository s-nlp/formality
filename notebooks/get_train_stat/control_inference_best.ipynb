{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6573a9-53da-4595-968c-88842eb5e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e46e111-d300-48e7-aef5-6774592be563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_gyafc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (AutoModelForSequenceClassification,  \n",
    "                          AutoTokenizer)\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789b5096-ff8b-424f-80f3-2d09896f5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_gyafc(\"microsoft/deberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c6a18e-473a-45f3-bac7-0c43ae1aed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e33ab96-9d67-4895-93dc-36ead8e70f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=64,\n",
    "            # num_workers=4,\n",
    "            drop_last=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd529893-07d0-464c-b6ce-3bd3ec573604",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = \"microsoft_deberta-base_ep5_wus1000_lr1e-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2789b9a8-68a3-412e-850f-a73926a279a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = f\"../trained_models/{md}/nli_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec81612-7151-4462-990b-09222cad425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(trained_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398da2f0-2f1a-4db8-aae6-b9e9385bb5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0358d7e-c051-42d1-992b-2ab522150fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "list_predited_label = []\n",
    "list_label = []\n",
    "with torch.no_grad():\n",
    "    for d in test_dataloader:\n",
    "        input_ids = d[\"input_ids\"].to(device) # .reshape(64, 24)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs[0]\n",
    "\n",
    "        _, prediction = torch.max(logits, dim=1)\n",
    "        targets = d[\"labels\"].detach().numpy().tolist()\n",
    "        prediction = prediction.cpu().detach().numpy().tolist()\n",
    "\n",
    "        list_label.extend(targets)\n",
    "        list_predited_label.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8537bf7a-8749-4c90-b04b-bb03a79bf8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "list_predited_label_1 = []\n",
    "list_label = []\n",
    "with torch.no_grad():\n",
    "    for d in test_dataloader:\n",
    "        input_ids = d[\"input_ids\"].to(device) # .reshape(64, 24)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs[0]\n",
    "\n",
    "        _, prediction = torch.max(logits, dim=1)\n",
    "        targets = d[\"labels\"].detach().numpy().tolist()\n",
    "        prediction = prediction.cpu().detach().numpy().tolist()\n",
    "\n",
    "        list_label.extend(targets)\n",
    "        list_predited_label_1.extend(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1972198e-7647-4414-96d2-5f3a0b917c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 41600})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_stupid = [a==b for a,b in zip(list_predited_label, list_predited_label_1)]\n",
    "Counter(check_stupid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c45bbce-b06b-4676-88ef-59a4f3824971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"../trained_models/{md}/test_predicts.json\") as f:\n",
    "    list_predited_label_saved = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c612edfb-3b80-4e57-b1fb-00d4023fae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"GYAFC_test_labels.json\") as f:\n",
    "    labels_saved = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d460244-0631-4417-b84d-04f8497585f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 41600})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_stupid_labels = [a==b for a,b in zip(list_label, labels_saved)]\n",
    "Counter(check_stupid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5264f1-6ec4-41c9-a5c6-4634b8ab6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_predited_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d63a1094-a365-4f5c-be0c-46ccdf80a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_predited_label_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaeecdb6-d2bc-4b57-affe-daad38158bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41600, 41600)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_predited_label), len(list_predited_label_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a429a0e1-40e7-42f9-8240-597aa3e8af98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 32847, False: 8753})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = [a==b for a,b in zip(list_predited_label, list_predited_label_saved)]\n",
    "Counter(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6ba98de-777d-473d-b621-73461d27308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.818     0.962     0.884     22151\n",
      "           1      0.946     0.756     0.840     19449\n",
      "\n",
      "    accuracy                          0.866     41600\n",
      "   macro avg      0.882     0.859     0.862     41600\n",
      "weighted avg      0.878     0.866     0.864     41600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list_label, list_predited_label, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23263601-5d55-435e-96fc-c51966b27f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.818     0.962     0.884     22151\n",
      "           1      0.946     0.756     0.840     19449\n",
      "\n",
      "    accuracy                          0.866     41600\n",
      "   macro avg      0.882     0.859     0.862     41600\n",
      "weighted avg      0.878     0.866     0.864     41600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list_label, list_predited_label_saved, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d17078b4-c44b-4b20-b401-b2a353e49f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 32847, False: 8753})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([a==b for a,b in zip(list_predited_label, list_predited_label_saved)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d6df7f2-9265-443c-9f1a-039b7fd739ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.818     0.962     0.884     22151\n",
      "           1      0.946     0.756     0.840     19449\n",
      "\n",
      "    accuracy                          0.866     41600\n",
      "   macro avg      0.882     0.859     0.862     41600\n",
      "weighted avg      0.878     0.866     0.864     41600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_saved, list_predited_label, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72d26a54-244e-4d37-9ad1-3df2b40fa87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.818     0.962     0.884     22151\n",
      "           1      0.946     0.756     0.840     19449\n",
      "\n",
      "    accuracy                          0.866     41600\n",
      "   macro avg      0.882     0.859     0.862     41600\n",
      "weighted avg      0.878     0.866     0.864     41600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels_saved, list_predited_label_saved, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffafaae-97c7-432c-8f74-6dff59d8e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a,b in zip(list_predited_label, list_predited_label_saved):\n",
    "#     if a!=b:\n",
    "#         print(a,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
